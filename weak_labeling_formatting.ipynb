{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXjiW_MQNgxJ"
      },
      "source": [
        "Classifying 4500 unlabeled text with weak labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeGVneinO72C",
        "outputId": "2b8f3e75-549a-464f-a503-049027671fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '6188_Recipe_Text_Classification'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 31 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (31/31), 1.08 MiB | 4.30 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DagimB/6188_Recipe_Text_Classification.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mD0IDnKsPau0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:1: SyntaxWarning: invalid escape sequence '\\e'\n",
            "<>:1: SyntaxWarning: invalid escape sequence '\\e'\n",
            "C:\\Users\\dagim\\AppData\\Local\\Temp\\ipykernel_15712\\3474560478.py:1: SyntaxWarning: invalid escape sequence '\\e'\n",
            "  model_path = \"output\\experiment-1\\experiment-1_best-model\"\n"
          ]
        }
      ],
      "source": [
        "model_path = \"output\\experiment-1\\experiment-1_best-model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1OsPzuehw-TQ"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def score_records(input_file, model_path, threshold):\n",
        "    # Load spaCy model\n",
        "    nlp = spacy.load(model_path)\n",
        "\n",
        "    # List to store processed records\n",
        "    processed_records = []\n",
        "\n",
        "    # Process each record in the input JSONL file\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            record = json.loads(line)\n",
        "\n",
        "            # Process text with spaCy model\n",
        "            doc = nlp(record['text'])\n",
        "\n",
        "            # Get categories and their scores\n",
        "            cats = {label: score for label, score in doc.cats.items()}\n",
        "\n",
        "            # Add accept field based on threshold\n",
        "            accept = [label for label, score in cats.items() if score >= threshold]\n",
        "\n",
        "            # Construct options\n",
        "            options = [{'id': label, 'text': label, 'meta': f'{score:.2f}'} for label, score in cats.items()]\n",
        "\n",
        "            # Construct final record\n",
        "            processed_record = {\n",
        "                'text': record['text'],\n",
        "                'cats': cats,\n",
        "                'accept': accept,\n",
        "                'answer': 'accept' if accept else 'reject',\n",
        "                'options': options\n",
        "            }\n",
        "\n",
        "            # Append processed record to the list\n",
        "            processed_records.append(processed_record)\n",
        "\n",
        "    # Output processed records to a new JSONL file\n",
        "    output_file = input_file.replace('.jsonl', '_processed.jsonl')\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for record in processed_records:\n",
        "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
        "\n"
        "input_file = 'data/unlabeled_train.jsonl'\n",
        "threshold = 0.5\n",
        "score_records(input_file, model_path, threshold)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
