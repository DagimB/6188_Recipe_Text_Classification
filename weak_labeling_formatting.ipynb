{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Classifying 4500 unlabeled text with weak labels"
      ],
      "metadata": {
        "id": "LXjiW_MQNgxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/DagimB/6188_Recipe_Text_Classification/main/data/unlabeled_train.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5wLYOFPOSEu",
        "outputId": "70939b1d-9237-415e-a97f-c3d421f5939e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-16 03:06:20--  https://raw.githubusercontent.com/DagimB/6188_Recipe_Text_Classification/main/data/unlabeled_train.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1200786 (1.1M) [text/plain]\n",
            "Saving to: ‘unlabeled_train.jsonl’\n",
            "\n",
            "unlabeled_train.jso 100%[===================>]   1.14M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-03-16 03:06:21 (21.0 MB/s) - ‘unlabeled_train.jsonl’ saved [1200786/1200786]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DagimB/6188_Recipe_Text_Classification.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeGVneinO72C",
        "outputId": "2b8f3e75-549a-464f-a503-049027671fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '6188_Recipe_Text_Classification'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 31 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (31/31), 1.08 MiB | 4.30 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the spaCy model within the cloned repository\n",
        "model_path = \"/content/6188_Recipe_Text_Classification/output/experiment-1/model-best\""
      ],
      "metadata": {
        "id": "mD0IDnKsPau0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OsPzuehw-TQ"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def score_records(input_file, model_path, threshold):\n",
        "    nlp = spacy.load(model_path)\n",
        "\n",
        "    processed_records = []\n",
        "\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            record = json.loads(line)\n",
        "\n",
        "            doc = nlp(record['text'])\n",
        "\n",
        "            cats = {label: score for label, score in doc.cats.items()}\n",
        "\n",
        "            accept = [label for label, score in cats.items() if score >= threshold]\n",
        "\n",
        "            options = [{'id': label, 'text': label, 'meta': f'{score:.2f}'} for label, score in cats.items()]\n",
        "\n",
        "\n",
        "            processed_record = {\n",
        "                'text': record['text'],\n",
        "                'cats': cats,\n",
        "                'accept': accept,\n",
        "                'answer': 'accept' if accept else 'reject',\n",
        "                'options': options\n",
        "            }\n",
        "\n",
        "\n",
        "            processed_records.append(processed_record)\n",
        "\n",
        "\n",
        "    output_file = input_file.replace('.jsonl', '_processed.jsonl')\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for record in processed_records:\n",
        "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
        "\n",
        "input_file = 'unlabeled_train.jsonl'\n",
        "threshold = 0.5\n",
        "score_records(input_file, model_path, threshold)\n"
      ]
    }
  ]
}